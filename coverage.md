## HW4 Testing & CI

Было произведено тестирование написанного мною алгоритма KMeans из HW2 по ML. Для сравнения был использован алгоритм KMeans из пакета sklearn.cluster. Тесты были параметризованы двумя инициализаторами: "k-means++" и "random". Также в качестве параметра были переданы 500 случайно сгенерированных выборок с точками для классификации. Таким образом, общее число параметризованных тестов составляет 2 * 500 = 1000.

```bash
============================= test session starts ==============================
platform darwin -- Python 3.8.8, pytest-6.2.3, py-1.10.0, pluggy-0.13.1
rootdir: /Users/ivansalenek/Documents/Учёба/Инженерные практики/ML HW2
plugins: anyio-2.2.0, cov-3.0.0
collected 1000 items                                                           

test_sample.py ....................................................F.... [  5%]
........................................................................ [ 12%]
........................................................................ [ 20%]
.....F......................F........................................... [ 27%]
........................................................................ [ 34%]
......................F................................................. [ 41%]
................................................F....................... [ 48%]
..........F............................................................. [ 56%]
....................................F................................... [ 63%]
..............................F......................................... [ 70%]
.............F.......................................................... [ 77%]
.....................................F....F............................. [ 84%]
.......F..F............................................................. [ 92%]
........F............................................................... [ 99%]
.......                                                                  [100%]


============================ 1000 passed in 18.85s =============================
```
Так как алгоритмы выбирают центры кластеров случайно, нельзя ожидать что все точки будут классифицированы одинаково, поэтому в assert я использовал проверку, что хотя бы 95% точек классифицированы правильно. Тем не менее видно, что иногда даже такого "трешхолда" оказывалось недостаточно. Это связано с тем, что алгоритм KMeans из пакета sklearn.cluster работает более "умно", чем мой алгоритм (как минимум несколько раз запускает k-means на одном датасете), поэтому на некоторых спецефических наборах данных кластеры сильно оличаются. Однако тот факт, что было провалено всего 14 тестов из 1000 говорит о том, что в целом мой KMeans работает более менее правильно на нормальных данных.


```bash
Name              Stmts   Miss  Cover   Missing
-----------------------------------------------
src/__init__.py       0      0   100%
src/kmeans.py        49      2    96%   73-74
test_sample.py       25      1    96%   31
-----------------------------------------------
TOTAL                74      3    96%
```

Данный тест практически полностью покрыл написанный мною алгоритм KMeans, за исключением 2х строчек, в которых я задаю "sample" инициализатор центров ксластеров. Такого инициализатора нет в KMeans из sklearn.cluster, однако работает он очень просто, так что в нем точно нет ошибок.

